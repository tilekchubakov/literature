Knowledge Enhanced Pre-trained Models

## Table of Contents
- [Syntax-aware models](#syntax-aware)
- [Trees](#semantically-aware)
- [Grounding](#grounding)
- [Knowledge retrieval](#knowledge retrieval)

 ## Syntax-aware
 - [Syntax-BERT: Improving Pre-trained Transformers with Syntax Trees](https://arxiv.org/abs/2103.04350)
 - [LIMIT-BERT : Linguistic Informed Multi-Task BERT](https://arxiv.org/abs/1910.14296)
 
 ## Semantically-aware
  - [SenseBERT: Driving Some Sense into BERT](https://arxiv.org/abs/1908.05646)
  - [Specializing Unsupervised Pretraining Models for Word-Level Semantic Similarity](https://arxiv.org/abs/1909.02339)

 ## Grounding
 - [Knowledge Enhanced Contextual Word Representations](https://arxiv.org/abs/1909.04164)
 - [ERNIE: Enhanced Language Representation with Informative Entities](https://arxiv.org/abs/1905.07129)
 
 ## Knowledge retrieval
 - [Enhancing Pre-Trained Language Representations with Rich Knowledge for Machine Reading Comprehension](https://aclanthology.org/P19-1226/)
 - [Barack's Wife Hillary: Using Knowledge-Graphs for Fact-Aware Language Modeling](https://arxiv.org/abs/1906.07241)
 - [Graph-Based Reasoning over Heterogeneous External Knowledge for Commonsense Question Answering](https://arxiv.org/abs/1909.05311)
 https://github.com/DecstionBack/AAAI_2020_CommonsenseQA
 - [Language Generation with Multi-Hop Reasoning on Commonsense Knowledge Graph](https://aclanthology.org/2020.emnlp-main.54.pdf)
 - [KG-BART: Knowledge Graph-Augmented BART for Generative Commonsense Reasoning](https://arxiv.org/abs/2009.12677)
 - [REALM: Retrieval-Augmented Language Model Pre-Training](https://arxiv.org/abs/2002.08909)
 - [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401)
 
 
